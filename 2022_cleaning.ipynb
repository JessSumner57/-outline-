{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd9a993-f078-4a2d-a9ed-8e5d7f58fe78",
   "metadata": {},
   "source": [
    "# Cleaning 2022 Inside Airbnb Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1253431-27d0-4424-a9ca-3e3b8615a1cd",
   "metadata": {},
   "source": [
    "### Importing Packages\n",
    "Here, I am taking the main packages from throughout the practicals as well as some of the functions that Jon uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5ca7204-525c-4c83-9b8c-4609559b2c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<jemalloc>: MADV_DONTNEED does not work (memset will be used instead)\n",
      "<jemalloc>: (This is the expected behaviour if you are running under QEMU)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import re\n",
    "import math\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# All of these are potentially useful, though\n",
    "# not all have been used in this practical --\n",
    "# I'd suggest exploring the use of different \n",
    "# Scalers/Transformers as well as clustering \n",
    "# algorithms...\n",
    "import sklearn\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, PowerTransformer\n",
    "from sklearn.cluster import KMeans, DBSCAN, OPTICS\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import random\n",
    "random.seed(42)    # For reproducibility\n",
    "np.random.seed(42) # For reproducibility\n",
    "\n",
    "# Make numeric display a bit neater\n",
    "pd.set_option('display.float_format', lambda x: '{:,.2f}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d3bc1d0-d4e1-4731-bb11-02b9f7dde05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are specific to NLP\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from nltk import ngrams, FreqDist\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = ToktokTokenizer()\n",
    "mms  = MinMaxScaler(feature_range=(-1,1))\n",
    "stds = StandardScaler()\n",
    "rbs  = RobustScaler()\n",
    "pts  = PowerTransformer()\n",
    "\n",
    "import string\n",
    "import unicodedata\n",
    "from bs4 import BeautifulSoup\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ab8376-0ba8-4d44-8420-c0e4f50329ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the Cache Function Jon wrote\n",
    "import os\n",
    "from requests import get\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def cache_data(src:str, dest:str) -> str:\n",
    "    \"\"\"Downloads and caches a remote file locally.\n",
    "    \n",
    "    The function sits between the 'read' step of a pandas or geopandas\n",
    "    data frame and downloading the file from a remote location. The idea\n",
    "    is that it will save it locally so that you don't need to remember to\n",
    "    do so yourself. Subsequent re-reads of the file will return instantly\n",
    "    rather than downloading the entire file for a second or n-th itme.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    src : str\n",
    "        The remote *source* for the file, any valid URL should work.\n",
    "    dest : str\n",
    "        The *destination* location to save the downloaded file.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A string representing the local location of the file.\n",
    "    \"\"\"\n",
    "    \n",
    "    url = urlparse(src) # We assume that this is some kind of valid URL \n",
    "    fn  = os.path.split(url.path)[-1] # Extract the filename\n",
    "    dfn = os.path.join(dest,fn) # Destination filename\n",
    "    \n",
    "    # Check if dest+filename does *not* exist -- \n",
    "    # that would mean we have to download it!\n",
    "    if not os.path.isfile(dfn) or os.path.getsize(dfn) < 1:\n",
    "        \n",
    "        print(f\"{dfn} not found, downloading!\")\n",
    "\n",
    "        # Convert the path back into a list (without)\n",
    "        # the filename -- we need to check that directories\n",
    "        # exist first.\n",
    "        path = os.path.split(dest)\n",
    "        \n",
    "        # Create any missing directories in dest(ination) path\n",
    "        # -- os.path.join is the reverse of split (as you saw above)\n",
    "        # but it doesn't work with lists... so I had to google how\n",
    "        # to use the 'splat' operator! os.makedirs creates missing\n",
    "        # directories in a path automatically.\n",
    "        if len(path) >= 1 and path[0] != '':\n",
    "            os.makedirs(os.path.join(*path), exist_ok=True)\n",
    "            \n",
    "        # Download and write the file\n",
    "        with open(dfn, \"wb\") as file:\n",
    "            response = get(src)\n",
    "            file.write(response.content)\n",
    "            \n",
    "        print('Done downloading...')\n",
    "\n",
    "    else:\n",
    "        print(f\"Found {dfn} locally!\")\n",
    "\n",
    "    return dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6f47ddc-7327-4b46-ae65-700039e1e2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the Plotting Function Jon wrote\n",
    "def plt_ldn(w, b):\n",
    "    \"\"\"\n",
    "    Creates a new figure of a standard size with the \n",
    "    water (w) and boundary (b) layers set up for easy\n",
    "    plotting. Right now this function assumes that you're\n",
    "    looking at London, but you could parameterise it in\n",
    "    other ways ot allow it to work for other areas.\n",
    "    \n",
    "    w: a water layer for London\n",
    "    b: a borough (or other) boundary layer for London\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, figsize=(14, 12))\n",
    "    w.plot(ax=ax, color='#79aef5', zorder=2)\n",
    "    b.plot(ax=ax, edgecolor='#cc2d2d', facecolor='None', zorder=3)\n",
    "    ax.set_xlim([502000,563000])\n",
    "    ax.set_ylim([155000,201500])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    return fig, ax\n",
    "\n",
    "########################\n",
    "# These may no longer be relevant because of changes to geopandas API\n",
    "\n",
    "def default_cmap(n, outliers=False):\n",
    "    cmap = mpl.cm.get_cmap('viridis_r', n)\n",
    "    colors = cmap(np.linspace(0,1,n))\n",
    "    if outliers:\n",
    "        gray = np.array([225/256, 225/256, 225/256, 1])\n",
    "        colors = np.insert(colors, 0, gray, axis=0)\n",
    "    return ListedColormap(colors)\n",
    "\n",
    "# mappable = ax.collections[-1] if you add the geopandas\n",
    "# plot last.\n",
    "def add_colorbar(mappable, ax, cmap, norm, breaks, outliers=False):\n",
    "    cb = fig.colorbar(mappable, ax=ax, cmap=cmap, norm=norm,\n",
    "                    boundaries=breaks,\n",
    "                    extend=('min' if outliers else 'neither'), \n",
    "                    spacing='uniform',\n",
    "                    orientation='horizontal',\n",
    "                    fraction=0.05, shrink=0.5, pad=0.05)\n",
    "    cb.set_label(\"Cluster Number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d24b7c5-d8fe-46f5-bc22-c14868b1eb01",
   "metadata": {},
   "source": [
    "### Reading in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7fe96b6-9b82-410a-abb4-75ee97261505",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings2022 = pd.read_csv('listings_2022.csv')\n",
    "listings2022.to_feather('listings_2022.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f164403-0a6a-469e-bfc2-5fe1a61e17d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame is 69,351 x 75\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data frame is {listings2022.shape[0]:,} x {listings2022.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efdaec16-f3a5-4911-b84a-e12d565ea9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bottom-left corner is -0.5236, 51.27248\n",
      "The top-right corner is 0.30515, 51.70893\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "<class 'geopandas.geoseries.GeoSeries'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 0         $50.00\n",
       "1         $75.00\n",
       "2         $90.00\n",
       "3         $55.00\n",
       "4        $379.00\n",
       "          ...   \n",
       "69346     $55.00\n",
       "69347    $201.00\n",
       "69348    $246.00\n",
       "69349    $250.00\n",
       "69350    $134.00\n",
       "Name: price, Length: 69351, dtype: object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Longitude and Latitude in Geographically Usable Data\n",
    "\n",
    "print(f\"The bottom-left corner is {listings2022.longitude.min()}, {listings2022.latitude.min()}\")\n",
    "print(f\"The top-right corner is {listings2022.longitude.max()}, {listings2022.latitude.max()}\")\n",
    "\n",
    "geo_listings2022 = gpd.GeoDataFrame(listings2022,geometry=gpd.points_from_xy(listings2022 .longitude, listings2022 .latitude, crs='epsg:4326'))\n",
    "geo_listings2022.to_crs('epsg:27700')\n",
    "\n",
    "#check the type\n",
    "print(type(geo_listings2022))\n",
    "print(type(geo_listings2022.geometry))\n",
    "geo_listings2022.price.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "569771bb-7f18-4d4d-8a17-de047add7a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>source</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>picture_url</th>\n",
       "      <th>host_id</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>license</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty GeoDataFrame\n",
       "Columns: [id, listing_url, scrape_id, last_scraped, source, name, description, neighborhood_overview, picture_url, host_id, host_url, host_name, host_since, host_location, host_about, host_response_time, host_response_rate, host_acceptance_rate, host_is_superhost, host_thumbnail_url, host_picture_url, host_neighbourhood, host_listings_count, host_total_listings_count, host_verifications, host_has_profile_pic, host_identity_verified, neighbourhood, neighbourhood_cleansed, neighbourhood_group_cleansed, latitude, longitude, property_type, room_type, accommodates, bathrooms, bathrooms_text, bedrooms, beds, amenities, price, minimum_nights, maximum_nights, minimum_minimum_nights, maximum_minimum_nights, minimum_maximum_nights, maximum_maximum_nights, minimum_nights_avg_ntm, maximum_nights_avg_ntm, calendar_updated, has_availability, availability_30, availability_60, availability_90, availability_365, calendar_last_scraped, number_of_reviews, number_of_reviews_ltm, number_of_reviews_l30d, first_review, last_review, review_scores_rating, review_scores_accuracy, review_scores_cleanliness, review_scores_checkin, review_scores_communication, review_scores_location, review_scores_value, license, instant_bookable, calculated_host_listings_count, calculated_host_listings_count_entire_homes, calculated_host_listings_count_private_rooms, calculated_host_listings_count_shared_rooms, reviews_per_month, geometry]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 76 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for na\n",
    "geo_listings2022[~(geo_listings2022.price.str.startswith('$', na=False))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57f1f970-69cb-498d-9a95-301723cb0c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbourhood_group_cleansed                   69351\n",
       "calendar_updated                               69351\n",
       "license                                        69351\n",
       "bathrooms                                      69351\n",
       "host_about                                     32405\n",
       "neighborhood_overview                          29387\n",
       "neighbourhood                                  29386\n",
       "host_response_time                             26521\n",
       "host_response_rate                             26521\n",
       "host_neighbourhood                             25754\n",
       "host_acceptance_rate                           24261\n",
       "review_scores_value                            17837\n",
       "review_scores_checkin                          17836\n",
       "review_scores_location                         17834\n",
       "review_scores_communication                    17803\n",
       "review_scores_accuracy                         17802\n",
       "review_scores_cleanliness                      17789\n",
       "review_scores_rating                           16780\n",
       "reviews_per_month                              16780\n",
       "last_review                                    16780\n",
       "first_review                                   16780\n",
       "host_location                                  12367\n",
       "bedrooms                                        3429\n",
       "description                                     1519\n",
       "beds                                            1200\n",
       "bathrooms_text                                   131\n",
       "name                                              21\n",
       "host_is_superhost                                 19\n",
       "host_identity_verified                             5\n",
       "host_total_listings_count                          5\n",
       "host_listings_count                                5\n",
       "host_picture_url                                   5\n",
       "host_thumbnail_url                                 5\n",
       "host_since                                         5\n",
       "host_name                                          5\n",
       "host_has_profile_pic                               5\n",
       "minimum_maximum_nights                             3\n",
       "minimum_nights_avg_ntm                             3\n",
       "maximum_maximum_nights                             3\n",
       "maximum_minimum_nights                             3\n",
       "minimum_minimum_nights                             3\n",
       "maximum_nights_avg_ntm                             3\n",
       "availability_90                                    0\n",
       "calculated_host_listings_count_shared_rooms        0\n",
       "number_of_reviews                                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for columns with most na values\n",
    "geo_listings2022.isna().sum().sort_values(ascending=False).head(45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a24f5-f856-4d35-8b61-016a18f4aeb2",
   "metadata": {},
   "source": [
    "Thoughts: we should not uses neighbourhood as a field or any about the reviews because we will lose so many listings. Also we should not use info about bathrooms, liscence (does that mean all the listings don't have licenses or they're not displayed? if so, maybe that could be a policy to show they're complying). A substantial amount of hosts do not list a location - also leads to the question if a host might have multiple locations?\n",
    "\n",
    "I'll drop the following rows that have na values: description (make a new dataset with just the decriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad08d67d-aacc-4ae0-8c69-354fa1776768",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.id.isna()].index.array, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ef6444-79c1-4d04-bd0d-f83144e17cbc",
   "metadata": {},
   "source": [
    "### Just Numeric Data Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb788c05-7619-4af5-a756-a493d4ce60a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add code from prac5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c528bf3b-bc6e-4ac7-8f2e-fd040dd80a5d",
   "metadata": {},
   "source": [
    "### Dataset for NLP Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
